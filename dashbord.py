import streamlit as st
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import PCA
import plotly.express as px
import plotly.graph_objects as go
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.neural_network import MLPClassifier

# Configuration de la page
st.set_page_config(
    page_title="Dashboard Classification des Claims üìä",
    layout="wide"
)

# Fonction pour charger les donn√©es
@st.cache_data
def load_data():
    try:
        # V√©rification de l'existence des fichiers avant de les charger
        data_dir = "data"
        required_files = ["train.csv", "test.csv", "X.csv", "y.csv", "train_data.csv"]
        
        # V√©rifier si les fichiers requis existent
        for file in required_files:
            if not os.path.exists(os.path.join(data_dir, file)):
                st.error(f"Fichier manquant: {os.path.join(data_dir, file)}")
                return None
        
        # Charger les fichiers de base
        train = pd.read_csv(os.path.join(data_dir, "train.csv"))
        test = pd.read_csv(os.path.join(data_dir, "test.csv"))
        X = pd.read_csv(os.path.join(data_dir, "X.csv"))
        y = pd.read_csv(os.path.join(data_dir, "y.csv"))
        train_data = pd.read_csv(os.path.join(data_dir, "train_data.csv"))
        
        # Charger les fichiers optionnels
        data_dict = {
            "train": train,
            "test": test,
            "X": X,
            "y": y,
            "train_data": train_data,
        }
        
        # Charger les fichiers de pr√©diction s'ils existent
        optional_files = {
            "test": "test.csv",
            "summary_metrics": "summary_metrics.csv",
            "test_final_prediction": "test_final_prediction.csv",
            "test_pred_xgb": "test_pred_xgb.csv",
            "test_pred_rf": "test_pred_rf.csv",
            "test_pred_log": "test_pred_log.csv",
            "test_pred_svm": "test_pred_svm.csv",
            "test_pred_knn": "test_pred_knn.csv"
        }
        
        for key, filename in optional_files.items():
            file_path = os.path.join(data_dir, filename)
            if os.path.exists(file_path):
                data_dict[key] = pd.read_csv(file_path)
            else:
                st.warning(f"Fichier optionnel non trouv√©: {file_path}")
                data_dict[key] = None
        
        return data_dict
    
    except Exception as e:
        st.error(f"Erreur lors du chargement des donn√©es: {str(e)}")
        import traceback
        st.error(f"D√©tails: {traceback.format_exc()}")
        return None
# Fonction pour charger les mod√®les
@st.cache_resource
def load_models():
    try:
        models = {}
        model_files = {
            "XGBoost": "models/xgb_model.pkl",
            "Random Forest": "models/rf_model.pkl",
            "Logistic Regression": "models/log_model.pkl",
            "SVC": "models/svm_model.pkl",
            "KNN": "models/knn_model.pkl",
        }
        
        for name, file in model_files.items():
            if os.path.exists(file):
                with open(file, "rb") as f:
                    models[name] = pickle.load(f)
        
        return models
    except Exception as e:
        st.error(f"Erreur lors du chargement des mod√®les: {e}")
        return {}

# Titre principal
st.title("üîç Dashboard : Car Insurance Claim Prediction")
st.markdown("*Pr√©dire si le titulaire d√©posera une r√©clamation dans les 6 prochains mois ou non.*")

# Sidebar pour la navigation
st.sidebar.title("Navigation")
page = st.sidebar.radio(
    "S√©lectionnez une page:",
    ["Aper√ßu des donn√©es", "Analyse exploratoire", "Performances des mod√®les", "Pr√©dictions", "Analyse PCA","Pr√©diction personnalis√©e"]
)

# Chargement des donn√©es
data = load_data()
if data is None:
    st.warning("Impossible de charger les donn√©es. Veuillez v√©rifier les chemins des fichiers.")
    st.stop()

# Chargement des mod√®les (si disponibles)
models = load_models()

# Page: Aper√ßu des donn√©es
if page == "Aper√ßu des donn√©es":
    st.header("üìã Aper√ßu des Donn√©es")
    
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("Informations sur les jeux de donn√©es")
        st.write(f"**Data initiale:** {data['train'].shape[0]} lignes, {data['train'].shape[1]} colonnes")
        st.write(f"**Data initiale apr√®s cleaning:** {data['train_data'].shape[0]} lignes, {data['train'].shape[1]} colonnes")
        st.write(f"**Data de test:** {data['test'].shape[0]} lignes, {data['test'].shape[1]} colonnes")
        
        
    
    with col2:
        st.subheader("Distribution de la classe cible")
        fig, ax = plt.subplots(figsize=(8, 6))
        class_counts = data['train']['is_claim'].value_counts()
        ax.pie(class_counts, labels=['Non-Claim', 'Claim'], autopct='%1.1f%%', 
               colors=['#66b3ff', '#ff9999'], explode=[0, 0.1])
        ax.set_title("R√©partition des classes")
        st.pyplot(fig)
    # Types des colonnes
    if st.checkbox("Afficher les types de colonnes"):
        col_types = pd.DataFrame({
            'Type': data['train'].dtypes,
            'Non-Null Count': data['train'].count(),
            'Null Count': data['train'].isnull().sum()
        })
        st.dataframe(col_types)
    st.subheader("Aper√ßu des donn√©es d'entra√Ænement")
    st.dataframe(data['train'].head(10))
    if st.checkbox("Afficher les statistiques descriptives"):
            st.subheader("Statistiques descriptives")
            st.dataframe(data['train'].describe())
    st.subheader("Aper√ßu des donn√©es apr√©s cleaning")
    st.dataframe(data['train_data'].head(10))
    if st.checkbox("Afficher les statistiques descriptives(apr√®s cleaning)"):
            st.subheader("Statistiques descriptives")
            st.dataframe(data['train_data'].describe())
   

# Page: Analyse exploratoire
elif page == "Analyse exploratoire":
    st.header("üîé Analyse Exploratoire des Donn√©es")
    
    tab1, tab2, tab3 = st.tabs(["Distributions", "Corr√©lations", "Feature Importance"])
    
    with tab1:
        st.subheader("Distribution des variables num√©riques")
        st.subheader("Feature Engineering")
        
        # Afficher les bool√©ens convertis
        boolean_cols = [col for col in data['train'].columns if 'is_' in col]
        
        if len(boolean_cols) > 0:
            st.write("Variables bool√©ennes converties:")
            
            # Afficher la distribution des variables bool√©ennes
            # Cr√©er un DataFrame pour la vue d'ensemble
            bool_summary = pd.DataFrame(index=boolean_cols)
            
            for col in boolean_cols:
                if col in data['train'].columns:
                    bool_summary.loc[col, 'Pourcentage de Yes'] = (data['train'][col] == 'Yes').mean() * 100 if data['train'][col].dtype == 'object' else data['train'][col].mean() * 100
                    bool_summary.loc[col, 'Pourcentage de No'] = 100 - bool_summary.loc[col, 'Pourcentage de Yes']
            
            bool_summary = bool_summary.sort_values('Pourcentage de Yes', ascending=False)
            
            # Afficher avec Plotly
            fig = go.Figure()
            
            fig.add_trace(go.Bar(
                y=bool_summary.index,
                x=bool_summary['Pourcentage de Yes'],
                name='Yes',
                orientation='h',
                marker=dict(color='#ff9999')
            ))
            
            fig.add_trace(go.Bar(
                y=bool_summary.index,
                x=bool_summary['Pourcentage de No'],
                name='No',
                orientation='h',
                marker=dict(color='#66b3ff')
            ))
            
            fig.update_layout(
                title="Distribution des variables bool√©ennes",
                xaxis_title="Pourcentage",
                barmode='stack',
                height=500
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
        
        # S√©lection de colonnes pour visualisation
        num_columns = data['X'].select_dtypes(include=['float64', 'int64']).columns.tolist()
        selected_cols = st.multiselect(
            "S√©lectionnez les colonnes √† visualiser:", 
            num_columns,
            default=num_columns[:5]
        )
        
        if selected_cols:
            col1, col2 = st.columns(2)
            with col1:
                # Histogrammes
                for col in selected_cols:
                    fig, ax = plt.subplots(figsize=(8, 4))
                    sns.histplot(data=data['train_data'], x=col, hue='is_claim', kde=True, ax=ax)
                    ax.set_title(f"Distribution de {col}")
                    st.pyplot(fig)
            
            with col2:
                # Boxplots
                for col in selected_cols:
                    fig, ax = plt.subplots(figsize=(8, 4))
                    sns.boxplot(data=data['train_data'], x='is_claim', y=col, ax=ax)
                    ax.set_title(f"Boxplot de {col} par classe")
                    ax.set_xticklabels(['Non-Claim', 'Claim'])
                    st.pyplot(fig)
    
    with tab2:
        st.subheader("Matrice de Corr√©lation")
        
        # Matrice de corr√©lation
        corr_matrix = data['X'].corr()
        subset=corr_matrix.abs().mean().sort_values(ascending=False).index
        corr_matrix = corr_matrix.loc[subset, subset]
        
        fig, ax = plt.subplots(figsize=(18, 10))
        mask = np.triu(np.ones_like(corr_matrix, dtype=bool))
        cmap = sns.diverging_palette(230, 20, as_cmap=True)
        sns.heatmap(data=corr_matrix, annot=False, fmt=".2f", cmap='coolwarm', square=True,linewidths=1)
        
        ax.set_title('Matrice de Corr√©lation des Variables')
        st.pyplot(fig)
        
        # Top corr√©lations
        st.subheader("Bar Corr√©lations")
        
        def get_top_correlations(corr_matrix):
            corr_pairs = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_pairs.append(
                        (corr_matrix.columns[i], corr_matrix.columns[j], 
                         corr_matrix.iloc[i, j])
                    )
            return corr_pairs
        
        top_corrs = get_top_correlations(corr_matrix)

        top_corrs_df = pd.DataFrame(
            top_corrs, columns=['Variable 1', 'Variable 2', 'Corr√©lation']
        ).sort_values(by='Corr√©lation', ascending=False)
        
        fig = px.bar(
            top_corrs_df, 
            x='Corr√©lation', 
            y=[f"{row['Variable 1']} - {row['Variable 2']}" for _, row in top_corrs_df.iterrows()],
            orientation='h',
            color='Corr√©lation',
            color_continuous_scale=px.colors.diverging.RdBu_r,  # <--- le coupable
            range_color=[-1, 1]
        )
        fig.update_layout(height=600, title_text=" corr√©lations")
        st.plotly_chart(fig, use_container_width=True)
        st.dataframe(top_corrs_df)

    
    with tab3:
        st.subheader("Importance des Features")
        
        # Recr√©er le SelectKBest pour l'importance des features
        from sklearn.preprocessing import StandardScaler
        from sklearn.feature_selection import SelectKBest, f_classif
        
        X_arr = data['X'].values
        y_arr = data['y'].values.ravel()
        
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X_arr)
        
        selector = SelectKBest(score_func=f_classif, k=20)
        selector.fit(X_scaled, y_arr)
        
        # Cr√©er un DataFrame pour l'importance
        feature_scores = pd.DataFrame({
            'Feature': data['X'].columns,
            'Score': selector.scores_
        })
        feature_scores = feature_scores.sort_values('Score', ascending=False).head(20)
        
        # Afficher avec Plotly
        fig = px.bar(
            feature_scores, 
            x='Score', 
            y='Feature',
            orientation='h',
            color='Score',
            color_continuous_scale='viridis'
        )
        fig.update_layout(height=600, title_text="Top 20 des features importantes (ANOVA F-value)")
        st.plotly_chart(fig, use_container_width=True)

# Page: Performances des mod√®les
elif page == "Performances des mod√®les":
    st.header("üìà Performances des Mod√®les")
    
    # Metrics globales
    st.subheader("Comparaison des m√©triques")
    
    # Visualisation des m√©triques
    metrics = data['summary_metrics'].set_index('Model')
    
    # Graphique de comparaison
    fig = go.Figure()
    metrics_cols = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
    
    for model in metrics.index:
        fig.add_trace(go.Bar(
            x=metrics_cols,
            y=metrics.loc[model, metrics_cols],
            name=model
        ))
    
    fig.update_layout(
        title="Comparaison des m√©triques par mod√®le",
        xaxis_title="M√©trique",
        yaxis_title="Score",
        legend_title="Mod√®le",
        barmode='group',
        height=500
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    # Visualisation sous forme de tableau
    st.dataframe(metrics)
    
    # Matrices de confusion
    st.subheader("Matrices de confusion")
    
    col1, col2, col3 = st.columns(3)
    
    # Fonction pour cr√©er les matrices de confusion √† partir des pr√©dictions
    def create_confusion_matrix(true_labels, predictions, title):
        cm = confusion_matrix(true_labels, predictions)
        fig, ax = plt.subplots(figsize=(4, 3))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
        ax.set_title(title)
        ax.set_xlabel("Pr√©dit")
        ax.set_ylabel("R√©el")
        return fig
    
    # Si les pr√©dictions sur le jeu de test √©taient disponibles
    if not len(models) > 0:
        # Utiliser le jeu de validation pour les matrices de confusion
        # Note: Cette partie n√©cessiterait d'avoir sauvegard√© les pr√©dictions de validation
        st.info("Les matrices de confusion n√©cessitent d'avoir sauvegard√© les pr√©dictions de validation.")
    else:
        # Utiliser les images sauvegard√©es si disponibles
        try:
            col1.image("visuals/confusion_xgboost.png", caption="Matrice de confusion - XGBoost")
            col2.image("visuals/confusion_rf.png", caption="Matrice de confusion - Random Forest")
            col3.image("visuals/confusion_log.png", caption="Matrice de confusion - Logistic Regression")
            
            col1, col2, col3 = st.columns(3)
            col1.image("visuals/confusion_svm.png", caption="Matrice de confusion - SVM")
            col2.image("visuals/confusion_knn.png", caption="Matrice de confusion - KNN")
            col3.image("visuals/confusion_mlp.png", caption="Matrice de confusion - MLP")
        except:
            st.warning("Les images des matrices de confusion ne sont pas disponibles.")

# Page: Pr√©dictions
elif page == "Pr√©dictions":
    st.header("üîÆ Analyse des Pr√©dictions")
    
    # Analyse des pr√©dictions finales
    st.subheader("Pr√©dictions sur la data de test lorsque au moins un mod√®le pr√©dit 'claim'")
    
    # Tableau de pr√©dictions
    prediction_cols = [col for col in data['test_final_prediction'].columns if 'is_claim' in col]
    
    # Cr√©er une colonne de vote majoritaire
    if len(prediction_cols) > 0:
        test_predictions = data['test_final_prediction'][prediction_cols].copy()
        test_predictions['vote_majoritaire'] = test_predictions.mean(axis=1).round()
        
        # Afficher les pr√©dictions
        st.dataframe(test_predictions[(test_predictions['is_claim_xgb'] == 1) | (test_predictions['is_claim_rf'] == 1) 
| (test_predictions['is_claim_log'] == 1)| (test_predictions['is_claim_svm'] == 1) 
| (test_predictions['is_claim_knn'] == 1)])
        
        # Distribution des pr√©dictions
        st.subheader("Distribution des pr√©dictions")
        
        # Compter les pr√©dictions positives par mod√®le
        model_counts = test_predictions.sum().sort_values(ascending=False)
        
        fig = px.bar(
            x=model_counts.index,
            y=model_counts.values,
            labels={'x': 'Mod√®le', 'y': 'Nombre de pr√©dictions "claim"'},
            title="Nombre de pr√©dictions positives par mod√®le"
        )
        st.plotly_chart(fig, use_container_width=True)
        
        # Histogramme des votes
        fig = px.histogram(
            test_predictions.sum(axis=1), 
            title="Distribution du nombre de mod√®les pr√©disant 'claim'",
            labels={'value': 'Nombre de mod√®les pr√©disant "claim"', 'count': 'Nombre d\'instances'}
        )
        st.plotly_chart(fig, use_container_width=True)
        st.subheader("Sous forme de tableau")
        st.dataframe(test_predictions.sum(axis=1).value_counts().reset_index(name='count').rename(columns={'index': 'Nombre de mod√®les pr√©disant "claim"'}))
        
        # Pr√©dictions unanimes
        st.subheader("Pr√©dictions unanimes")
        unanimous_positive = test_predictions[test_predictions.sum(axis=1) == len(prediction_cols) - 1]  
        unanimous_negative = test_predictions[test_predictions.sum(axis=1) == 0]
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("Pr√©dictions unanimes 'claim' (80%)", len(unanimous_positive))
        with col2:
            st.metric("Pr√©dictions unanimes 'non-claim'", len(unanimous_negative))
        
        # Afficher les instances avec pr√©dictions unanimes positives
        if len(unanimous_positive) > 0:
            st.subheader("Instances unanimement pr√©dites comme 'claim'")
            unanimously_positive_indices = unanimous_positive.index
            st.dataframe(data['test'].loc[unanimously_positive_indices])
    else:
        st.warning("Aucune colonne de pr√©diction trouv√©e dans les donn√©es.")

# Page: Analyse PCA
elif page == "Analyse PCA":
    st.header("üß™ Analyse PCA")
    st.subheader("Analyse en Composantes Principales (PCA)")
        
        # Recr√©er la PCA
    from sklearn.preprocessing import StandardScaler
        
    X_arr = data['X'].values
    y_arr = data['y'].values.ravel()
        
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_arr)
        
    # Appliquer PCA
    pca = PCA()
    X_pca = pca.fit_transform(X_scaled)
        
    # Variance expliqu√©e
    cumulative_variance = np.cumsum(pca.explained_variance_ratio_)
        
    fig = px.line(
            x=range(1, len(cumulative_variance)+1),
            y=cumulative_variance,
            markers=True,
            title="Variance expliqu√©e cumul√©e par composante PCA",
            labels={"x": "Nombre de composantes", "y": "Variance expliqu√©e cumul√©e"}
        )
        
    fig.add_hline(y=0.95, line_dash="dash", line_color="red", 
                     annotation_text="95% de variance expliqu√©e", 
                     annotation_position="bottom right")
        
    st.plotly_chart(fig, use_container_width=True)
        
    # Visualisation 2D des donn√©es apr√®s PCA
    if len(X_pca) > 0:
            st.subheader("Visualisation des donn√©es apr√®s PCA")
            
            # Cr√©er un DataFrame pour la visualisation
            pca_df = pd.DataFrame({
                'PC1': X_pca[:, 0],
                'PC2': X_pca[:, 1],
                'Classe': y_arr
            })
            
            fig = px.scatter(
                pca_df, 
                x='PC1', 
                y='PC2', 
                color='Classe',
                color_discrete_map={0: '#66b3ff', 1: '#ff9999'},
                title="Projection des donn√©es sur les deux premi√®res composantes principales",
                labels={'Classe': 'Classe (0: Non-Claim, 1: Claim)'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Loadings des composantes principales
            st.subheader("Contributions des features aux composantes principales")
            
            n_features = min(10, len(data['X'].columns))
            loadings = pca.components_[:2, :].T  # Prendre les 2 premi√®res composantes
            
            loadings_df = pd.DataFrame({
                'Feature': data['X'].columns,
                'PC1': loadings[:, 0],
                'PC2': loadings[:, 1]
            })
            
            # Tri par importance sur PC1
            loadings_df = loadings_df.sort_values('PC1', key=abs, ascending=False).head(n_features)
            
            fig = px.bar(
                loadings_df,
                x='Feature',
                y=['PC1', 'PC2'],
                barmode='group',
                title=f"Contributions des {n_features} features les plus importantes aux PC1 et PC2",
                labels={'value': 'Contribution', 'variable': 'Composante principale'}
            )
            
            st.plotly_chart(fig, use_container_width=True)
    
# Page: Pr√©diction personnalis√©e
elif page == "Pr√©diction personnalis√©e":
    st.header("üîÆ Pr√©diction Personnalis√©e")
    
    # Formulaire pour la saisie des donn√©es
    st.subheader("Entrez les valeurs des features")
    
    # Cr√©er un formulaire pour la saisie des donn√©es
    with st.form(key='prediction_form'):
        input_data = {}
        for col in data['X'].columns:
            input_data[col] = st.number_input(f"Valeur de {col}", value=0.0, step=0.01)
        
        submit_button = st.form_submit_button(label='Faire une pr√©diction')
    
    if submit_button:
        # Convertir les donn√©es d'entr√©e en DataFrame
        input_df = pd.DataFrame([input_data])
        
        # Normaliser les donn√©es d'entr√©e
        
        
        # Faire des pr√©dictions avec chaque mod√®le
        predictions = {}
        for model_name, model in models.items():
            predictions[model_name] = model.predict(input_df)[0]
        
        # Afficher les r√©sultats
        st.subheader("R√©sultats de la pr√©diction")
        for model_name, prediction in predictions.items():
            st.write(f"{model_name}: {'Claim' if prediction == 1 else 'Non-Claim'}")
        st.subheader("Vote majoritaire")
        vote_majoritaire = sum(predictions.values()) / len(predictions)
        st.write(f"Vote majoritaire: {'Claim' if vote_majoritaire >= 0.5 else 'Non-Claim'}")

    
    
        
            

# Pied de page
st.markdown("---")
st.markdown("*Dashboard cr√©√© avec Streamlit pour l'analyse des donn√©es de classification*")